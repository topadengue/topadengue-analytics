# -*- coding: utf-8 -*-
"""topadengue.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r3frZIi9qZHWtraor_oeIZSIzcMFViZN

# Preprocesamiento

Leemos los datos y preprocesamos
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

data = pd.read_csv("/content/drive/My Drive/TopaDenguePY Compartido/Datos TopaDengue/paraguay/R/TopaDengue/data_transformation_R/full_data_frame.csv" , encoding='latin-1',sep = ";")
data.head()

data = data[["consortium", "breeding_site_code_tpd", "zona_i", "visit_day", "visit_month", "T", "V", "H", "breading_site_positive"]]
data = data.rename(columns={"T": "temperature", "V": "wind", "H": "humidity", "zona_i": "zone"})
data.head()

data.dtypes

data.columns[data.isna().any()].tolist()

data_no_na = data.dropna(axis=0)

data_no_na.columns[data_no_na.isna().any()].tolist()

"""# Exploratory Data Analysis

## Analisis Univariado
"""

# Count by consortium
data_no_na.groupby(["consortium"])["breading_site_positive"].count().plot(kind="bar")

data_no_na.groupby(["breeding_site_code_tpd"])["breading_site_positive"].count().plot(kind="bar")

data_no_na.groupby(["zone"])["breading_site_positive"].count().plot(kind="bar")

import seaborn as sns

sns.distplot(data_no_na["temperature"], rug=True);

sns.distplot(data_no_na["wind"], rug=True);

sns.distplot(data_no_na["humidity"], rug=True);

sns.distplot(data_no_na["visit_month"], rug=True);

"""## Analisis bivariado"""

data_no_na.boxplot(column="temperature", by="breading_site_positive")

data_no_na.boxplot(column="wind", by="breading_site_positive")

data_no_na.boxplot(column="humidity", by="breading_site_positive")

data_no_na.groupby(["zone", "breading_site_positive"])["visit_month"].count()

data_no_na.groupby(["breeding_site_code_tpd", "breading_site_positive"])["visit_month"].count() \
  .unstack('breading_site_positive').plot(kind="bar", stacked=True)

"""## Análisis de 3 variables"""

sns.scatterplot(x="temperature", y="humidity", hue="breading_site_positive", data=data_no_na)

sns.scatterplot(x="temperature", y="wind", hue="breading_site_positive", data=data_no_na)

sns.scatterplot(x="wind", y="humidity", hue="breading_site_positive", data=data_no_na)

len(data_no_na)

"""## ML Training"""

import pandas as pd
import statistics
from sklearn.model_selection import cross_validate

def makePrediction(model, X_train, y_train, scoring, output_list):
  results = cross_validate(model, X_train, y_train, cv=5, scoring=scoring, return_train_score=True)
  output_list.append({'Model': type(model).__name__, 'Scoring': scoring , 'AvgScorage': statistics.mean(results["test_score"]) })

data_encoded_dummy = pd.get_dummies(data_no_na, columns=["consortium", "breeding_site_code_tpd", "zone"])
data_encoded_dummy.head()

X = data_encoded_dummy.drop(columns=["breading_site_positive"])
y = data_encoded_dummy["breading_site_positive"]

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
scorages = []
models = [LogisticRegression(solver="lbfgs", class_weight="balanced"), GaussianNB()]
scorings = ['average_precision','balanced_accuracy','recall']

for model in models:
  for scoring in scorings: 
    makePrediction(model = model, scoring = scoring, X_train = X_train, y_train = y_train, output_list = scorages)
    
scoragesDataFrame = pd.DataFrame(scorages)

# scoragesDataFrame.groupby(["Model"]).plot(kind="bar", stacked=True)

def color(val):
    if val <= 0.5:
      color = '#e74c3c'
    elif val > 0.5 and val <= 0.6:
      color = '#e67e22'
    elif val > 0.6 and val <=0.75:
      color = '#f1c40f'
    elif val > 0.75 and val <=0.9:
      color = '#27ae60'
    elif val > 0.9:
      color = '#2ecc71'
    return 'color: %s' % color

def highlight_max(s):
    is_max = s == s.max()
    return ['border-style: solid;' if v else '' for v in is_max]

scoragesDataFrame.style.\
    applymap(color, subset=['AvgScorage']).\
    apply(highlight_max,subset=['AvgScorage'])

from sklearn.preprocessing import LabelEncoder

data_encoded_label = data_no_na.copy()
categorical_columns = ["consortium", "breeding_site_code_tpd", "zona"]

for c in categorical_columns:
  le = LabelEncoder()
  le.fit(data_encoded_label[c])
  data_encoded_label[c] = le.transform(data_encoded_label[c])

data_encoded_label.head()

X = data_encoded_label.drop(columns=["breading_site_positive"])
y = data_encoded_label["breading_site_positive"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=300, max_depth=5, class_weight="balanced", random_state=0)
cross_validate(rf, X_train, y_train, cv=5, scoring="average_precision", return_train_score=True)

rf.fit(X_train, y_train)
feat_importances = pd.Series(rf.feature_importances_, index=X.columns)
feat_importances.nlargest(10).plot(kind='barh')

from sklearn.metrics import precision_recall_curve, average_precision_score
import matplotlib.pyplot as plt
from inspect import signature


y_score = rf.predict_proba(X_test)[:, 1]
precision, recall, _ = precision_recall_curve(y_test, y_score)

# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument
step_kwargs = ({'step': 'post'}
               if 'step' in signature(plt.fill_between).parameters
               else {})
plt.step(recall, precision, color='b', alpha=0.2,
         where='post')
plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.0])
plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(
          average_precision_score(y_test, y_score)))

from sklearn.ensemble import AdaBoostClassifier
from sklearn.utils.class_weight import compute_sample_weight

sw = compute_sample_weight("balanced", y_train)
ab = AdaBoostClassifier()
ab.fit(X_train, y_train, sample_weight=sw)

y_score = ab.predict_proba(X_test)[:, 1]
average_precision_score(y_test, y_score)

"""# Machine *Learning*

# Validación
"""